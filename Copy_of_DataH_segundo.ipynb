{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of DataH_segundo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulo01012018/iris-facens/blob/master/Copy_of_DataH_segundo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "k1USE8J0xhky",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Segundo exemplo - Localizando Clusters com K-Means**\n",
        "\n",
        "Adaptado do trabalho de  [Philip Kalinda](http://www.philipkalinda.com/ds3.html).\n",
        "\n",
        "O notebook original pode ser encontrado no github neste [endereço](https://github.com/philipkalinda/data_science/blob/master/multiclass_logistic_classification_and_kmeans_clustering_of_iris_dataset/multiclass_logistic_classification_and_kmeans_clustering_of_iris_dataset.ipynb)\n",
        "\n",
        "\\\n",
        "**Descrição**\n",
        "\n",
        "Nesta análise, continuaremos a exploração do Iris Dataset.\n",
        "E, em especial, este dataset pode ser explorado de diferentes formas, dependendo dos objetivos almejados quando se inicia a análise.\n",
        "\n",
        "\\\n",
        "**Objetivos**\n",
        "\n",
        "Para que a nossa análise seja eficiente, é importante definir um escopo e objetivos antes de realizar qualquer análise tendo apenas algumas poucas perguntas para nos guiar, sob a pena de nos perdermos nos dados ou nos desviarmos para análises que não acrescentam valor às nossas metas.\n",
        "Assim, selecionamos os seguintes objetivos:\n",
        "\n",
        "1.       Verificar agrupamentos identificáveis nos dados\n",
        "2.       Avaliar a precisão destes agrupamentos em função das espécies.\n",
        "3.       Criar um modelo para predizer as espécies dos exemplos\n",
        "4.       Avaliar a acurácia do modelo preditivo\n",
        "5.       Avaliar a capacidade do modelo em prever cada espécie\n",
        "6.       Avaliar a acurácia do modelo em predizer dados exemplo.\n",
        "\n",
        "\\\n",
        "**Perguntas a Pesquisar**\n",
        "\n",
        "Existem algumas perguntas que procuraremos responder para atingir os objetivos, conforme apresentado a seguir:\n",
        "\n",
        "1.       Qual das abordagens é a mais precisa?\n",
        "2.       Como cada variável interage com as demais?\n",
        "3.       Como cada variável influencia na predição da espécie?\n",
        "4.       Qual espécie é mais fácil de ser prevista? Porque?\n",
        "5.       E qual espécie é mais difícil de ser prevista? Porque?\n"
      ]
    },
    {
      "metadata": {
        "id": "NkbwPP40F288",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Estas serão as bibliotecas que vamos utilizar ao longo deste texto:\n",
        "\n",
        "\\\n",
        "O **Sklearn** é \"O\" pacote quando pensamos em criar soluções de machine learning em python. \n",
        "\n",
        "O **Pandas** é um pacote fenomenal para tratar de conjuntos de dados, e possui muitas funções úteis. \n",
        "\n",
        "O **NumPY** é o pacote para funções de álgebra linear e possui algumas funções e métodos úteis. \n",
        "\n",
        "O **Matplotlib** é o pacote para construir visualizações. \n",
        "\n",
        "E, finalmente, o **Seaborn** torna as visualizações mais interessantes e bonitas."
      ]
    },
    {
      "metadata": {
        "id": "HUJdQ3BL3fHS",
        "colab_type": "code",
        "outputId": "ae03d3a3-11f4-445c-fbc5-2b20267ee577",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "cell_type": "code",
      "source": [
        "#Preparacao do ambiente\n",
        "#Bibliotecas que utilizaremos;\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.cross_validation import train_test_split, KFold, cross_val_score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f575e3bb0c42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.cross_validation'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ljTU_ApSJuwV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bq5a8q9N93JG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "------------------------------------\n",
        "\n",
        "Carregadas as bibliotecas, vamos aos dados!"
      ]
    },
    {
      "metadata": {
        "id": "h8mRdHcC3jCq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Definicao das especies\n",
        "def species_label(theta):\t\n",
        "  return raw_data.target_names[theta]\t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_JxO5voQ3mSv",
        "colab_type": "code",
        "outputId": "f27518c0-c328-4794-d071-684f21c97080",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "cell_type": "code",
      "source": [
        "raw_data = datasets.load_iris()\n",
        "data_desc = raw_data.DESCR\n",
        "data = pd.DataFrame(raw_data.data, columns=raw_data.feature_names)\n",
        "data['species'] = [species_label(theta) for theta in raw_data.target]\n",
        "data['species_id'] = raw_data.target\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-750ccf8e45c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_iris\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDESCR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'species'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mspecies_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'species_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "oxXCTiPw-M4C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Inicialmente, um pouco de limpeza nos dados é necessária.\n",
        "Uma vez que os dados tenham sido carregados para o dataframe, precisamos de uma coluna adicional conter o texto que descreve a espécie de forma que cada linha possa ser melhor identificada. Isto foi feito com o uso da função (“species_label()”) definida anteriormente.\n",
        "\n",
        "-----------------------"
      ]
    },
    {
      "metadata": {
        "id": "5BRki6h_JSg5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Descrever**\n",
        "\n",
        "Para nos tornarmos mais íntimos do dataset e começar a pavimentar a estrada que nos levará ao destino, vale a pena recuperar algumas análises estatísticas descritivas sobre os dados. \n",
        "Isto é simples de se executar, mas mesmo assim, agrega muito. valor. O conteúdo retornado é apresentado abaixo:\n"
      ]
    },
    {
      "metadata": {
        "id": "DSahmR663qLy",
        "colab_type": "code",
        "outputId": "7aaf60f4-aa27-4744-dc2c-b670d2cfe5ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2bb0b18689d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ICAqDjcZJ_e4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A tabela sumariza todas as colunas numéricas do dataset. É particularmente útil para se obter uma visão geral dos dados e sobre como eles estão estruturados. \n",
        "Por exemplo, observando o intervalo e os quartis, nós podemos identificar que o comprimento da pétala é a coluna com a maior variação e a largura da sépala a que tem menor variação.\n",
        "Isto pode ser útil quando nos aproximarmos do estágio da compreensão de como cada uma das variáveis afeta o modelo preditivo.\n",
        "\n",
        "-----------------------\n"
      ]
    },
    {
      "metadata": {
        "id": "bOj4rogJLdWn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Pivot Table**\n",
        "\n",
        "O ponto central da nossa análise está relacionado às espécies. Para desenvolver a compreensão de como cada uma das variáveis se comporta em cada espécie, nós podemos produzir uma Pivot Table com as médias.\n"
      ]
    },
    {
      "metadata": {
        "id": "2dgVn5Qw3tvJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data.pivot_table(index='species', values=['sepal length (cm)',\n",
        "                                          'sepal width (cm)',\n",
        "                                          'petal length (cm)',\n",
        "                                          'petal width (cm)',\n",
        "                                          'species_id'],aggfunc=np.mean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KOdamiELL4ai",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Nós podemos deduzir a partir desta tabela que, na média, o comprimento e largura das pétadas da Setosa são muito menores que da Versicolor e Virginica. Da mesma forma, a Virginica tem na média as maiores dimensões de pétadas. Nós também podemos ver que na média, os comprimentos das sépalas são muito próximos, contudo, a Setosa tem claramente larguras de sépalas maiores que das outras espécies. Ou seja, esta tabela nos mostra que a espécie Setosa tem várias características distintas.\n",
        "\n",
        "-----------------------\n"
      ]
    },
    {
      "metadata": {
        "id": "fVk1aMnEMy8-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Correlação**\n",
        "\n",
        "Uma outra forma de obter uma compreensão mais profunda da dinâmica das variáveis é através de uma tabela de correlação.\n",
        "Esta tabela identifica tendências entre as variáveis e assinala para estas um número entre -1 e 1, dependendo da intensidade da relação entre elas.\n",
        "\n",
        "\\\n",
        "**É importante notar que esta tabela meramente identifica tendências e não identifica a causa desta tendência nem indica que uma variável tem impacto sobre outra.**"
      ]
    },
    {
      "metadata": {
        "id": "okJH3LjB3wu6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "d_corr=data.iloc[:,[0,1,2,3,5]].corr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gBRyEWhR3zdM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "d_corr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jW_eNZrGO1iI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Esta tabela mostra que existe uma forte relação linear entre todas as variáveis, exceto a largura da sépala, que é muito mais fraca e também negativa. Esta pode ser uma informação útil na fase posterior.\n",
        "Olhando para a tabela de correlação, podemos ver que, em relação ao species_id, existem 3 variáveis principais (comprimento da sépala, comprimento da pétala e largura da pétala) que têm uma forte relação linear. Estas variáveis são provavelmente fortes variáveis na previsão das espécies de uma dada flor de íris.\n",
        "\n",
        "-----"
      ]
    },
    {
      "metadata": {
        "id": "UtdA0PoKPHho",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Informações Visuais**\n",
        "\n",
        "Agora que temos uma ideia do comportamento numérico dos dados, vamos dar uma olhada nos dados a partir de uma perspectiva visual.\n",
        "\n",
        "Vamos traçar gráficos de cada uma das variáveis, umas contra as outras.\n",
        "Como existem apenas 5 colunas numéricas, esse gráfico não será muito grande.\n",
        "\n",
        "Para manter o tema das espécies, podemos codificar cada ponto de dados por suas respectivas espécies.\n"
      ]
    },
    {
      "metadata": {
        "id": "eSoMvNjQ32aW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sns.set_style('whitegrid')\n",
        "sns.pairplot(data, hue='species')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6iAQGdf3PrV6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Isto nos mostra que as espécies estão bem separadas em grupos com base em suas medições. Este é o caso de todas as combinações, exceto ao traçar o comprimento da sépala e a largura da sépala. Estas são um pouco mais difíceis de separar.\n",
        "\n",
        "Embora as espécies de Setosa neste gráfico estejam menos agrupadas do que nos outros gráficos, Versicolor e Virginica estão muito bem misturadas aqui, tornando muito mais difícil distinguir um grupo do outro individualmente.\n",
        "\n",
        "--------------------------\n"
      ]
    },
    {
      "metadata": {
        "id": "ukHu6FAIQjrA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sns.set_style('whitegrid')\n",
        "plt.figure(figsize=(15,6))\n",
        "mask = np.zeros_like(d_corr, dtype=np.bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "sns.heatmap(d_corr,mask=mask, cmap=cmap, vmax=0.99,\n",
        "            square=True,\n",
        "            linewidths=.5, cbar_kws={\"shrink\": .5})\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wUqmMjPoQnfJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Acima há uma representação visual da matriz de correlação mencionada anteriormente. Isso deixa muito claro que a largura da sépala é muito diferente das outras variáveis as quais tendem a variar de forma conjunta com uma forte correlação linear positiva.\n",
        "\n",
        "------\n"
      ]
    },
    {
      "metadata": {
        "id": "zuOKlZIVRDyp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Agrupamentos através de K-Means**\n",
        "\n",
        "A visualização anterior nos disse muito sobre os dados e sugere que espécies semelhantes se agrupam através das dimensões de suas pétalas e sépalas. \n",
        "Vamos explorar isso! A técnica de agrupamento usada para explorar isso será o agrupamento K-Means. K-Means, é uma técnica de aprendizado de máquina sem supervisão. Apenas para explicar, o aprendizado de máquina não supervisionado é um ramo que se concentra na identificação de tendências e padrões nos dados. \n",
        "O K-Means se concentra especificamente em definir o número \"K\" de clusters. A forma como  cada ponto é associado a um cluster se baseia na distância euclidiana do dado em relação ao ponto central do cluster. Assim, cada um dos pontos de dados é associado ao cluster mais próximo e, depois que todos os pontos tiverem sido atribuídos, teremos pontos de dados com características semelhantes agrupados em cada cluster. \n",
        "Dependendo de seus objetivos, você pode ter quantos clusters quiser. No entanto, quanto mais clusters, menor a probabilidade de fazer suposições generalizadas sobre os dados. \n",
        "Neste caso, como temos três espécies, vamos tentar usar três clusters com a dimensão sépala e pétala dos dados e ver o que parece!\n",
        "\n",
        "------\n",
        "\n",
        "**K-Means com K=3**"
      ]
    },
    {
      "metadata": {
        "id": "BrC1_qDj357n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cluster_1_label(alpha):\n",
        "    if alpha == 0:\n",
        "        return 'virginica'\n",
        "    if alpha == 1:\n",
        "        return 'setosa'\n",
        "    if alpha == 2:\n",
        "        return 'versicolor'\n",
        "\n",
        "def cluster_2_label(beta):\n",
        "    if beta == 1 or beta == 7 or beta == 8:\n",
        "        return 'setosa'\n",
        "    if beta == 0 or beta == 3 or beta == 6:\n",
        "        return 'versicolor'\n",
        "    if beta == 2 or beta == 4 or beta == 5:\n",
        "        return 'virginica'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mvhl7mds39RI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# KMeans Cluster to explore data - 3 Clusters\n",
        "kmeans_model_1 = KMeans(n_clusters=3,random_state=123)\n",
        "\n",
        "distances_1 = kmeans_model_1.fit_transform(data.iloc[:,0:4])\n",
        "\n",
        "labels_1 = kmeans_model_1.labels_\n",
        "\n",
        "data['cluster_1']=labels_1\n",
        "data['cluster_1_label']=data['cluster_1'].apply(cluster_1_label)\n",
        "\n",
        "with sns.color_palette(\"hls\", 8):\n",
        "    sns.pairplot(data.iloc[:,[0,1,2,3,-2]], hue='cluster_1')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c2pqcj3MXBMZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Estes gráficos são muito parecidos com aqueles da sessão de \"Informações Visuais\".\n",
        "Isto pode ser bom porque pressupõe que os dados estão agrupados de forma semelhante aos rótulos das espécies, mas conseguimos isto apenas usando suas dimensões de sépala e pétalas. \n",
        "\n",
        "Vamos dar uma olhada em como o K-Means com K=3 agrupou as amostras contra suas respectivas espécies.\n"
      ]
    },
    {
      "metadata": {
        "id": "4EcBEdHT4AM8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "pd.crosstab(data['species'], labels_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "drHB9gI8X5oV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A tabela acima mostra que Setosa foi perfeitamente agrupada, no entanto, Versicolor e Virginica possuem um número de agrupamentos inconsistentes. Isso provavelmente se deve ao fato de a largura da sépala de ambas as espécies é relativamente indistinguível quando comparada ao comprimento da sépala. Talvez se houvesse mais clusters, eles poderiam ajudar a quebrar as áreas que estão misturadas entre as duas espécies e suas dimensões. \n",
        "\n",
        "Vamos tentar 9 clusters e ver que coisas interessantes podemos encontrar (nota: não foi utilizado nenhum método matemático para derivar o número de K, ele apenas foi escolhido aleatoriamente).\n",
        "\n",
        "----\n",
        "\n",
        "**K-Means com K=9**\n"
      ]
    },
    {
      "metadata": {
        "id": "tq6qBH0M4dGq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# KMeans Cluster to explore data - 9 Clusters\n",
        "kmeans_model_2 = KMeans(n_clusters=9,random_state=123)\n",
        "distances_2 = kmeans_model_2.fit_transform(data.iloc[:,0:4])\n",
        "labels_2 = kmeans_model_2.labels_\n",
        "data['cluster_2']=labels_2\n",
        "data['cluster_2_label']=data['cluster_2'].apply(cluster_2_label)\n",
        "data = data.iloc[:,[0,1,2,3,4,5,6,7,8,9]]\n",
        "sns.pairplot(data.iloc[:,[0,1,2,3,8]], hue='cluster_2')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bJeB6fICY9P3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Estes gráficos são um pouco mais difíceis de comparar com os gráficos originais, no entanto, é possível notar que há vários clusters distintos que se agrupam. \n",
        "\n",
        "Vamos dar uma olhada em como o K-Means com K=9 agrupou as amostras contra suas respectivas espécies."
      ]
    },
    {
      "metadata": {
        "id": "cGUqi5fa4gRM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pd.crosstab(data['species'],data['cluster_2'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g37Kwau6amRV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "O K-Means com K=9 agrupou os dados muito melhor do que o modelo anterior. O número de amostras agrupadas incorretamente é muito menor que o do cluster anterior. Escolhendo as espécies com mais contagens no cluster como o cluster de espécies designado, podemos somar todos os agrupamentos e ver quantos foram incorretamente agrupados usando a espécie como referência."
      ]
    },
    {
      "metadata": {
        "id": "6DgztMhl4jQ_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cluster_1_accuracy = len(data[data['species']==data['cluster_1_label']])/len(data)\n",
        "cluster_2_accuracy = len(data[data['species']==data['cluster_2_label']])/len(data)\n",
        "print('K=3 KMeans -> {0:.4f}%'.format(cluster_1_accuracy*100))\n",
        "print('K=9 KMeans -> {0:.4f}%'.format(cluster_2_accuracy*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x9uIXQlwa0L5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Uma forma eficaz de comparar os resultados do modelo seria calcular a precisão de cada modelo. \n",
        "\n",
        "Para fazer isso, você adicionaria todas as observações corretamente previstas e as dividiria pelo número total de observações (ou seja, corretamente previsto + incorretamente previsto). Quando fazemos isso, vemos que o cluster com K = 3 teve uma precisão de 89,33%, enquanto que o cluster K = 9  apresentou a precisão de 96,67%, o que é melhor!\n",
        "\n",
        "---\n",
        "\n",
        "\\\n",
        "#Modelagem de Classificação Logística Multi-Classe\n",
        "\n",
        "Vamos dar uma olhada na construção de um modelo que pode prever a qual espécie uma dada flor do gênero íris pertence com base nas dimensões de sua pétala e sépala.\n",
        "\n",
        "\n",
        "\\\n",
        "Precisamos construir um modelo que possa tomar uma série de dados e produzir uma saída que nos indique quais espécies a flor possui em função das variáveis de entrada fornecidas. \n",
        "\n",
        "\\\n",
        "Conforme já foi visto anteriormente, este ramo do aprendizado de máquina é chamado de aprendizado de máquina supervisionado.\n",
        "\n",
        "\\\n",
        "Este é um ramo da aprendizagem de máquina que se concentra em treinar um algoritmo para prever uma variável desconhecida a partir de variáveis conhecidas. \n",
        "\n",
        "\\\n",
        "A variável desconhecida que preveremos é a espécie da flor. O algoritmo que treinaremos é uma Regressão Logística.\n",
        "\n",
        "\\\n",
        "Uma vez que tentaremos prever as espécies de flores (que é representado por uma lista finita de opções categóricas - Setosa, Virginica, Versicolor), precisamos atribuir um valor numérico para cada uma das espécies dentro de variáveis dummy. \n",
        "\n",
        "\\\n",
        "Variáveis dummy são variáveis que recebem atribuições binárias (True = 1, False = 0) com base em cada categoria em uma determinada coluna. \n",
        "\n",
        "\\\n",
        "Por exemplo, nossas categorias são Setosa, Virginica e Versicolor. Nós teremos uma coluna para cada uma dessas espécies e atribuiremos 1 ou 0 para cada linha, dependendo de quais espécies elas pertencem. Portanto, uma linha da amostra representando Setosa terá o valor de coluna Setosa=1 e os valores Virginica e Versicolor serão designados como 0.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "FnOaVcu-4n3J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dummies = pd.get_dummies(data['species'],prefix='actual')\n",
        "data = pd.concat([data,dummies],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xEWS4Pyj4pBE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kuRUFFaQcolS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Aqui, as variáveis dummy são facilmente criadas e concatenadas aos dados principais graças aos métodos realmente úteis do Pandas.\n",
        "\n",
        "A forma como uma Regressão Logística funciona é muito semelhante a uma regressão linear, pois é preciso um número de entradas para fornecer uma saída, no entanto, a saída é onde está a diferença, pois usa a \"logit transformation\", que é uma mistura de uma transformação exponencial e uma transformação de normalização.\n",
        "\n",
        "A Regressão Logística é um modelo de classificação que gera a probabilidade de você estar em uma determinada classe. O limite para determinar qual probabilidade deve ser atribuída a um retorno positivo ou negativo é padronizado para 0,5 e pode ser ajustado dependendo de suas necessidades. Isso também é conhecido como o limiar de discriminação.\n",
        "\n",
        "Estes modelos estão focados em saídas binárias. No nosso caso, temos mais de duas saídas; temos 3 espécies para explicar. Então, para fazer isto, teremos que construir 3 modelos separados para cada uma das diferentes espécies. Cada modelo irá prever a chance de uma determinada entrada ser classificada como essa espécie ou não. Para cada linha, cada modelo calculará sua probabilidade e a mais alta das 3 será a espécie selecionada para aquela linha."
      ]
    },
    {
      "metadata": {
        "id": "G59rVygt4tPm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classifiers = ['versicolor','virginica','setosa']\n",
        "models = {}\n",
        "for mdl_idx in classifiers:\n",
        "    lgr_model = LogisticRegression()\n",
        "    lgr_model.fit(data.iloc[:,[0,1,2,3]],data['actual_{}'.format(mdl_idx)])\n",
        "    models[mdl_idx]=lgr_model\n",
        "models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jIAOIKtWhLFB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Os modelos foram montados e treinados utilizando todo o conjunto de dados e é assim que eles são configurados. Eles foram agrupados em um dicionário para que possam ser acessados através de um loop de forma segura.\n"
      ]
    },
    {
      "metadata": {
        "id": "ScyKoNa-4wGC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "coefs = {}\n",
        "for mdl_k, mdl_v in models.items():\n",
        "    coefs[mdl_k]=mdl_v.coef_\n",
        "coefs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dDxTmu_3hc2r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vamos dar uma olhada nos coeficientes do modelo para determinar como cada uma das variáveis afeta a variável dependente, que neste caso é a probabilidade de pertencer a uma determinada espécie. \n",
        "\n",
        "Aqui podemos ver o efeito que cada aumento de dimensão tem na probabilidade de ser classificado nas respectivas espécies. Cada coeficiente (k) representa o efeito (+ ve ou -ve) para cada aumento de 1 unidade na variável à qual eles estão atribuídos sobre a variável dependente."
      ]
    },
    {
      "metadata": {
        "id": "HS_0EQsn4ywh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lgr_probabilities = pd.DataFrame(columns=classifiers)\n",
        "for mdl_key, mdl_model in models.items():\n",
        "    lgr_probabilities[mdl_key] = mdl_model.predict_proba(data.iloc[:,[0,1,2,3]])[:,1]\n",
        "lgr_probabilities.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y6PBOKUUh1_0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Aqui nós calculamos as probabilidades para cada um dos modelos para que possamos determinar qual linha pertence a qual espécie de acordo com o modelo com maior probabilidade."
      ]
    },
    {
      "metadata": {
        "id": "5rbNM7pE4217",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predicted_species = lgr_probabilities.idxmax(axis=1)\n",
        "pred_spec = lgr_probabilities.max(axis=1)\n",
        "lgr_accuracy = len(data[data['species']==predicted_species])/len(data)\n",
        "print(\"Accuracy\", lgr_accuracy)\n",
        "pd.crosstab(data['species'],predicted_species)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CzcDX5VYh-uq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Aqui precisamos selecionar o maior valor em cada linha e usar o nome do índice da coluna para sabermos quais espécies o modelo prevê ter maior probabilidade de ser usada. Esta tabela mostra como as previsões se comparam aos valores reais."
      ]
    },
    {
      "metadata": {
        "id": "mXnF_-sU4587",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Logistic Regression Accuracy - {0:.4f}%'.format(lgr_accuracy*100));\n",
        "print('3-Cluster K-Means Clustering Accuracy - {0:.4f}%'.format(cluster_1_accuracy*100));\n",
        "print('9-Cluster K-Means Clustering Accuracy - {0:.4f}%'.format(cluster_2_accuracy*100));"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "470U84UviVBv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A acurácia deste modelo pode ser calculada da mesma forma que os modelos K-Means anteriores. \n",
        "\n",
        "Este cálculo resulta em uma precisão de 96,00%! \n",
        "\n",
        "Isto é apenas 0,67% menor do que o modelo K-Means dom K=9.\n",
        "\n",
        "---\n",
        "\n",
        "Vamos examinar um pouco mais a fundo cada um dos modelos usados para fazer essas previsões, para avaliarmos sua precisão.\n"
      ]
    },
    {
      "metadata": {
        "id": "9thV-S5l5JQB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log_setosa_fpr, log_setosa_tpr, log_setosa_thresholds = roc_curve(data['actual_setosa'],\n",
        "                                                                  lgr_probabilities['setosa'])\n",
        "log_versicolor_fpr, log_versicolor_tpr, log_versicolor_thresholds = roc_curve(data['actual_versicolor'],\n",
        "                                                                              lgr_probabilities['versicolor'])\n",
        "log_virginica_fpr, log_virginica_tpr, log_virginica_thresholds = roc_curve(data['actual_virginica'],\n",
        "                                                                           lgr_probabilities['virginica'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jbx_zZpziwmw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As duas métricas mais populares usadas na avaliação de modelos de classificação são a Taxa de Positivos Verdadeiros (TPR) e a Taxa de Falsos Positivos (FPR) do modelo. A taxa positiva real fornece informações sobre a capacidade do modelo de atribuir corretamente resultados positivos. Isso também é chamado de \"sensibilidade\" do modelo. A Taxa de Falsos Positivos fornece informações sobre a proporção de resultados que previmos como positivos quando eram negativos. Isso também é chamado de fallout do modelo.\n",
        "\n",
        "Quando você planeja essas duas medidas uma contra a outra, isso produz um gráfico conhecido como Curva ROC (Receiver Operator Characteristic). Essa curva nos permite entender o desempenho de um modelo de classificação à medida que o limiar de discriminação é variado. \n",
        "\n",
        "Ainda mais, a área sob a curva descreve a probabilidade de o classificador classificar uma observação positiva aleatória maior do que uma observação negativa aleatória. Isso é conhecido como a pontuação AUC (Área sob Curva). \n",
        "\n",
        "Vamos dar uma olhada nas Curvas ROC dos 3 modelos e no que eles poderiam nos dizer sobre cada modelo.\n",
        "\n",
        "Em cada gráfico, a linha pontilhada cinza indica a mesma probabilidade de predição (ou seja, 50/50).\n"
      ]
    },
    {
      "metadata": {
        "id": "Kfelr18s5PFR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "plt.xlim([-0.2, 1.2])\n",
        "plt.ylim([0, 1.2])\n",
        "plt.title('Setosa Model ROC Curve')\n",
        "plt.xlabel('log_setosa_fpr')\n",
        "plt.ylabel('log_setosa_tpr')\n",
        "plt.plot(log_setosa_fpr, log_setosa_tpr,c='r')\n",
        "plt.plot([0,1],[0,1], c='grey',ls=':')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gcl8cQLn5SNa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "plt.xlim([-0.2, 1.2])\n",
        "plt.ylim([0, 1.2])\n",
        "plt.title('Versicolor Model ROC Curve')\n",
        "plt.xlabel('log_versicolor_fpr')\n",
        "plt.ylabel('log_versicolor_tpr')\n",
        "plt.plot(log_versicolor_fpr, log_versicolor_tpr,c='g')\n",
        "plt.plot([0,1],[0,1], c='grey',ls=':')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P4jKXeVs5VBd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "plt.xlim([-0.2, 1.2])\n",
        "plt.ylim([0, 1.2])\n",
        "plt.title('Virginica Model ROC Curve')\n",
        "plt.xlabel('log_virginica_fpr')\n",
        "plt.ylabel('log_virginica_tpr')\n",
        "plt.plot(log_virginica_fpr, log_virginica_tpr,c='b')\n",
        "plt.plot([0,1],[0,1], c='grey',ls=':')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZhUumjsE5X45",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log_setosa_auc = roc_auc_score(data['actual_setosa'],lgr_probabilities['setosa'])\n",
        "log_versicolor_auc = roc_auc_score(data['actual_versicolor'],lgr_probabilities['versicolor'])\n",
        "log_virginica_auc = roc_auc_score(data['actual_virginica'],lgr_probabilities['virginica'])\n",
        "\n",
        "print('The AUC score for Sentosa Model - {0:.4f}%'.format(log_setosa_auc*100))\n",
        "print('The AUC score for Versicolor Model - {0:.4f}%'.format(log_versicolor_auc*100))\n",
        "print('The AUC score for Virginica Model - {0:.4f}%'.format(log_virginica_auc*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hp8EXcUpj4rF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**K-Fold Cross Validation**\n",
        "\n",
        "Estes modelos foram construídos a partir de todo o conjunto de dados e podem estar sujeitos a overfitting. \n",
        "\n",
        "O overfitting ocorre quando um modelo é bom apenas para prever os dados nos quais foi treinado, e o algoritmo não fornece uma solução generalizada suficiente que possa ser aplicada a dados ainda não vistos. \n",
        "\n",
        "Overfitting é um problema se você está construindo seu modelo para fazer previsões sobre dados sobre os quais ele nunca foi treinado. \n",
        "\n",
        "Para superar esse grande desafio, usaremos uma técnica de validação cruzada chamada\"K-Fold Cross Validation\".\n",
        "\n",
        "A validação cruzada supera o overfitting ao sub-definir os dados em um conjunto de treinamento e um conjunto de testes. \n",
        "Ao fazer isso, os modelos são treinados no conjunto de treinamento e testados usando o conjunto de testes que representaria os dados desconhecidos que o modelo está tentando prever. \n",
        "\n",
        "A K-Fold Cross Validation está basicamente repetindo o processo de validação cruzada K vezes.\n",
        "\n",
        "Cada iteração teria um treinamento e um conjunto de testes diferentes. Depois de executar K vezes, a precisão e as métricas médias são tomadas e transportadas como a precisão final e a métrica para a técnica de modelagem."
      ]
    },
    {
      "metadata": {
        "id": "ZGlM2Wo45h0r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# k fold cross validation of results\n",
        "kf = KFold(len(data), n_folds=10, shuffle=True, random_state=123)\n",
        "classifiers = ['versicolor','virginica','setosa']\n",
        "k_models = {}\n",
        "k_probabilities = {}\n",
        "k_accuracies = {}\n",
        "k_pred_spec = {}\n",
        "k_roc = {}\n",
        "k_auc = {}\n",
        "colors = ['m','y','k','#9500d8','#a6ff9b','#7f3a18','b','g','r','c']\n",
        "\n",
        "for mdl_idx, (train_idx, test_idx) in enumerate(kf):\n",
        "    train_data = data.iloc[train_idx]\n",
        "    test_data = data.iloc[test_idx]\n",
        "    models = {}\n",
        "    \n",
        "    for classer in classifiers:\n",
        "        model = LogisticRegression()\n",
        "        model.fit(train_data.iloc[:,[0,1,2,3]],train_data['actual_{}'.format(classer)])\n",
        "        models[classer]=model\n",
        "    k_models[mdl_idx]=models\n",
        "    temp_probabilities = pd.DataFrame(columns=classifiers)\n",
        "    \n",
        "    for mdl_key, mdl_model in k_models[mdl_idx].items():\n",
        "        temp_probabilities[mdl_key] = mdl_model.predict_proba(test_data.iloc[:,[0,1,2,3]])[:,1]\n",
        "        k_probabilities[mdl_idx]=temp_probabilities\n",
        "\n",
        "    for mdl_key, mdl_probs in k_probabilities[mdl_idx].items():\n",
        "        predicted_species = temp_probabilities.idxmax(axis=1)\n",
        "        pred_spec=temp_probabilities.max(axis=1)\n",
        "        #lgr_accuracy = len(test_data[test_data['species']==predicted_species])/len(test_data)\n",
        "        df1 = test_data['species'].reset_index(drop=True)\n",
        "        lgr_accuracy = len(df1==predicted_species)/len(test_data)\n",
        "        k_accuracies[mdl_idx]=lgr_accuracy\n",
        "        k_pred_spec[mdl_idx]=pred_spec\n",
        "    \n",
        "    roc={}\n",
        "    for classer in classifiers:\n",
        "        fpr, tpr, thresholds = roc_curve(test_data['actual_{}'.format(classer)],k_probabilities[mdl_idx][classer])\n",
        "        roc[classer]=(fpr,tpr,thresholds)\n",
        "    k_roc[mdl_idx]=roc\n",
        "    \n",
        "    auc={}\n",
        "    for classer in classifiers:\n",
        "        auc_score = roc_auc_score(test_data['actual_{}'.format(classer)],k_probabilities[mdl_idx][classer])\n",
        "        auc[classer]=auc_score\n",
        "    k_auc[mdl_idx]=auc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0YKy178-5kzZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for classer in classifiers:\n",
        "    plt.figure(figsize=(15,6))\n",
        "    plt.xlim([-0.2, 1.2])\n",
        "    plt.ylim([0, 1.2])\n",
        "    plt.title('{} Model ROC Curve'.format(classer))\n",
        "    plt.xlabel('{} False Positive Rate'.format(classer))\n",
        "    plt.ylabel('{} True Positive Rate'.format(classer))\n",
        "    for k, v in k_roc.items():\n",
        "        fpr = v[classer][0]\n",
        "        tpr = v[classer][1]\n",
        "        plt.plot(fpr, tpr, c=colors[k])\n",
        "    plt.plot([0,1],[0,1], c='grey',ls=':')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8DX5JeSY5nq3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "k_auc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V61VnU_Wkv1C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Aqui a técnica de validação cruzada mencionada anteriormente é executada usando K = 10. \n",
        "\n",
        "Isso significa que o processo de modelagem, previsão e pontuação foi executado 10 vezes. Um total de 3 * K = 10 (30) modelos foram construídos e testados.\n",
        "\n",
        "\n",
        "Os gráficos mostram que os modelos Setosa foram consistentes em predizer quais das amostras eram da espécie Setosa. A pontuação média da AUC para os modelos Setosa foi de 100,00%. \n",
        "\n",
        "Os modelos da Virginica só tinha um conjunto em que o modelo tinha um pequeno problema em predizer as espécies corretas, no entanto, a pontuação média da AUC foi de 99,63%. \n",
        "\n",
        "Os modelos Versicolor tiveram mais problemas em prever as espécies de cada amostra com pontuações AUC variando de 59,09% a 94,44%. A pontuação média da AUC para os modelos Versicolor foi de 80,04%. \n",
        "\n",
        "Com base nas pontuações da AUC, o grupo de modelos com melhor desempenho foi o grupo 3 com pontuações AUC de Setosa=100%, Versicolor=94,44% e Virginica=100,00%.\n"
      ]
    },
    {
      "metadata": {
        "id": "aCBPx8fV5rS2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "setosa_auc = 0\n",
        "versicolor_auc = 0\n",
        "virginica_auc = 0\n",
        "\n",
        "for k,v in k_auc.items():\n",
        "    setosa_auc += v['setosa']\n",
        "    versicolor_auc += v['versicolor']\n",
        "    virginica_auc += v['virginica']\n",
        "\n",
        "print('The Cross Validated AUC score for the Sentosa Model - {0:.4f}%'.format(setosa_auc*10))\n",
        "print('The Cross Validated AUC score for the Versicolor Model - {0:.4f}%'.format(versicolor_auc*10))\n",
        "print('The Cross Validated AUC score for the Virginica Model - {0:.4f}%'.format(virginica_auc*10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9KZRVIsKlVRG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Conclusão***\n",
        "\n",
        "Após a conclusão de nossa análise, agora podemos avaliar o quanto atingimos cada um de nossos objetivos e responder às perguntas que geraram as várias análises.\n",
        "\n",
        "*Objetivos*\n",
        "\n",
        "1. Verifique se há clusters identificáveis nos dados: Conseguimos usar o agrupamento K-Means para identificar padrões e o algoritmo tendia a agrupar os dados com base em suas espécies.\n",
        "\n",
        "2. Avaliar a precisão desses agrupamentos com base nas espécies: Pudemos avaliar a precisão dos métodos de agrupamento observando o número de pontos de dados corretamente categorizados em relação à toda a população.\n",
        "\n",
        "3. Construir um modelo para prever as espécies de amostras: Conseguimos construir um modelo preditivo para determinar as espécies das flores. O melhor moelo foi o modelo de regressão logística. Nós construímos um para cada espécie e usamos uma abordagem One Vs All.\n",
        "\n",
        "4. Avaliar a precisão das previsões do modelo com base nas espécies reais: Conseguimos avaliar a precisão dos modelos usando a mesma abordagem dos métodos de agrupamento.\n",
        "\n",
        "5. Avaliar a capacidade do modelo de prever cada espécie: Conseguimos atingir esse objetivo mergulhando cada vez mais fundo no modelo de cada espécie e calculando cada uma das suas pontuações na AUC.\n",
        "\n",
        "6. Avaliar a precisão do modelo para prever dados fora da amostra: Conseguimos avaliar a precisão do modelo em dados fora da amostra simulando isso com uma técnica de K-Fold Cross Validation.\n",
        "\n",
        "\n",
        "Também estamos em uma ótima posição para responder a todas as questões devido às descobertas em nossas análises.\n",
        "\n",
        "Questões de pesquisa\n",
        "1. Quais das duas abordagens são mais precisas? - Tendo utilizado medidas de precisão adequadas, podemos concluir que o cluster K-Means com K=9 foi o classificador mais preciso com uma pontuação de precisão de 96,67%.\n",
        "\n",
        "2. Como cada uma das variáveis interage umas com as outras? - Conseguimos identificar as relações entre as variáveis com o uso de uma matriz de correlação que nos permitiu identificar que 3 de 4 variáveis são altamente correlacionadas entre si e com a espécie.\n",
        "\n",
        "3. Como cada uma das variáveis influencia a previsão da espécie? - Examinamos os coeficientes de cada um dos modelos usados para determinar isto.\n",
        "\n",
        "4. Qual espécie é mais fácil de prever? Por quê? - Com base em cada uma das curvas ROC do modelo e nos modelos K-Means, a espécie mais fácil de prever é Setosa e isso se deve às características distintas da espécie que é bastante diferente das duas espécies restantes.\n",
        "\n",
        "5. Qual espécie é a mais difícil de prever? Por quê? - A espécie mais difíceis de prever com base na curva ROC e nos resultados da AUC é a espécie Versicolor. Seus atributos são muito semelhantes às espécies de Virginica, tornando muito difícil distingui-los uns dos outros. Isso fica claro em algumas parcelas e agrupamentos em que há uma quantidade razoável de sobreposição, mesmo no cluster K = 9. A espécie Versicolor é também está posicionada entre as duas outras espécies, tornando mais difícil definir um intervalo entre elas que não se enquadre em nenhuma outra espécie\n"
      ]
    }
  ]
}